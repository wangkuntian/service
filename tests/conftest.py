"""pytest é…ç½®æ–‡ä»¶

è¿™ä¸ªæ–‡ä»¶åŒ…å«æµ‹è¯•è¿è¡Œçš„å…¨å±€é…ç½®å’Œå…±äº«çš„fixturesã€‚
"""

import asyncio
import sys
import os
import pytest
from typing import Generator

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))


def pytest_configure(config):
    """pytesté…ç½®å‡½æ•°"""
    # æ³¨å†Œè‡ªå®šä¹‰æ ‡è®°
    config.addinivalue_line('markers', 'unit: å•å…ƒæµ‹è¯•æ ‡è®°')
    config.addinivalue_line('markers', 'integration: é›†æˆæµ‹è¯•æ ‡è®°')
    config.addinivalue_line('markers', 'performance: æ€§èƒ½æµ‹è¯•æ ‡è®°')
    config.addinivalue_line('markers', 'slow: æ…¢é€Ÿæµ‹è¯•æ ‡è®°ï¼ˆè¿è¡Œæ—¶é—´è¾ƒé•¿ï¼‰')


def pytest_collection_modifyitems(config, items):
    """ä¿®æ”¹æµ‹è¯•æ”¶é›†é¡¹ç›®"""
    # ä¸ºæ²¡æœ‰æ ‡è®°çš„æµ‹è¯•æ·»åŠ unitæ ‡è®°
    for item in items:
        if not any(item.iter_markers()):
            item.add_marker(pytest.mark.unit)


@pytest.fixture(scope='session')
def event_loop():
    """
    åˆ›å»ºäº‹ä»¶å¾ªç¯fixture
    ç¡®ä¿æ‰€æœ‰å¼‚æ­¥æµ‹è¯•ä½¿ç”¨åŒä¸€ä¸ªäº‹ä»¶å¾ªç¯
    """
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()

    yield loop

    # æ¸…ç†å¾…å¤„ç†çš„ä»»åŠ¡
    pending = asyncio.all_tasks(loop)
    if pending:
        loop.run_until_complete(
            asyncio.gather(*pending, return_exceptions=True)
        )

    if not loop.is_closed():
        loop.close()


@pytest.fixture(autouse=True)
def setup_test_environment():
    """
    è‡ªåŠ¨ä½¿ç”¨çš„æµ‹è¯•ç¯å¢ƒè®¾ç½®fixture
    åœ¨æ¯ä¸ªæµ‹è¯•å‰åè¿›è¡Œç¯å¢ƒæ¸…ç†
    """
    # æµ‹è¯•å‰è®¾ç½®
    original_env = os.environ.copy()

    yield

    # æµ‹è¯•åæ¸…ç†
    os.environ.clear()
    os.environ.update(original_env)


@pytest.fixture
def temp_dir(tmp_path):
    """
    æä¾›ä¸´æ—¶ç›®å½•çš„fixture
    """
    return tmp_path


# æ€§èƒ½æµ‹è¯•ç›¸å…³çš„fixtures
@pytest.fixture(scope='session')
def performance_threshold():
    """æ€§èƒ½æµ‹è¯•é˜ˆå€¼é…ç½®"""
    return {
        'init_time_ms': 5.0,
        'service_launch_time_ms': 10.0,
        'signal_handling_time_ms': 1.0,
        'health_check_time_ms': 5.0,
        'memory_usage_mb': 50.0,
    }


def pytest_runtest_setup(item):
    """æµ‹è¯•è¿è¡Œå‰çš„è®¾ç½®"""
    # æ£€æŸ¥æ˜¯å¦ä¸ºæ€§èƒ½æµ‹è¯•ï¼Œå¦‚æœæ˜¯ï¼Œè¾“å‡ºæ€§èƒ½æµ‹è¯•ä¿¡æ¯
    if 'performance' in [mark.name for mark in item.iter_markers()]:
        print(f'\nğŸš€ è¿è¡Œæ€§èƒ½æµ‹è¯•: {item.name}')


def pytest_runtest_teardown(item):
    """æµ‹è¯•è¿è¡Œåçš„æ¸…ç†"""
    # å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œç¡®ä¿å†…å­˜æµ‹è¯•çš„å‡†ç¡®æ€§
    import gc

    gc.collect()


# pytestæŠ¥å‘Šé’©å­
def pytest_terminal_summary(terminalreporter, exitstatus, config):
    """ç»ˆç«¯æ‘˜è¦æŠ¥å‘Š"""
    if hasattr(terminalreporter, 'stats'):
        # è·å–å„ç±»æµ‹è¯•ç»Ÿè®¡
        passed = len(terminalreporter.stats.get('passed', []))
        failed = len(terminalreporter.stats.get('failed', []))
        skipped = len(terminalreporter.stats.get('skipped', []))

        print(f'\nğŸ“Š æµ‹è¯•ç»Ÿè®¡:')
        print(f'   é€šè¿‡: {passed}')
        print(f'   å¤±è´¥: {failed}')
        print(f'   è·³è¿‡: {skipped}')

        # å¦‚æœæœ‰æ€§èƒ½æµ‹è¯•ï¼Œæ˜¾ç¤ºé¢å¤–ä¿¡æ¯
        performance_tests = [
            test
            for test in terminalreporter.stats.get('passed', [])
            if 'performance' in str(test.keywords)
        ]

        if performance_tests:
            print(f'   æ€§èƒ½æµ‹è¯•: {len(performance_tests)}')


# å¼‚æ­¥æµ‹è¯•è¶…æ—¶é…ç½®
@pytest.fixture(autouse=True)
def async_test_timeout():
    """ä¸ºå¼‚æ­¥æµ‹è¯•è®¾ç½®è¶…æ—¶"""
    return 30  # 30ç§’è¶…æ—¶


# é”™è¯¯å¤„ç†fixtures
@pytest.fixture
def capture_logs():
    """æ•è·æ—¥å¿—çš„fixture"""
    import logging
    import io

    log_capture = io.StringIO()
    handler = logging.StreamHandler(log_capture)
    logger = logging.getLogger()
    logger.addHandler(handler)

    yield log_capture

    logger.removeHandler(handler)


# Mockç›¸å…³çš„fixtures
@pytest.fixture
def mock_asyncio_sleep():
    """Mock asyncio.sleepä»¥åŠ é€Ÿæµ‹è¯•"""
    import asyncio
    from unittest.mock import patch, AsyncMock

    async def fast_sleep(delay):
        # å¿«é€Ÿç¡çœ ï¼Œä»…ç­‰å¾…å¾ˆçŸ­æ—¶é—´
        await asyncio.sleep(0.001)

    with patch('asyncio.sleep', side_effect=fast_sleep):
        yield


# æ•°æ®éªŒè¯fixtures
@pytest.fixture
def assert_performance(performance_threshold):
    """æ€§èƒ½æ–­è¨€helper"""

    def _assert_performance(
        metric_name: str, actual_value: float, threshold_key: str = None
    ):
        threshold_key = threshold_key or f'{metric_name}_ms'
        threshold = performance_threshold.get(threshold_key, float('inf'))
        assert actual_value < threshold, (
            f'{metric_name} è€—æ—¶ {actual_value:.2f}msï¼Œè¶…è¿‡ {threshold}ms é˜ˆå€¼'
        )

    return _assert_performance
